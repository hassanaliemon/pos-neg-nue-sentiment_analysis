{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "financial_sentiment_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVuevsbAbYIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "import nltk\n",
        "import random\n",
        "#nltk.download('punkt') # this line to download utilities, do it for the first time only\n",
        "\n",
        "path = '/content/Financial_News_Dataset.csv'\n",
        "df = pandas.read_csv(path, encoding=\"ISO-8859-1\", header=None)\n",
        "documents = []\n",
        "all_tok_words = []\n",
        "dic_cnt = {}\n",
        "dic_cnt['neutral']=dic_cnt['negative']=dic_cnt['positive']=0\n",
        "for index, row in df.iterrows():\n",
        "  category, description = row[0], row[1]\n",
        "  dic_cnt[category] +=1\n",
        "  if dic_cnt[category] < 601:#limiting the dataset to make it balanced\n",
        "    tok_word = nltk.tokenize.word_tokenize(description)\n",
        "    documents.append((tok_word, category))\n",
        "    for word in tok_word:\n",
        "      all_tok_words.append(word)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1tzroMZQgEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.shuffle(documents)\n",
        "all_words = nltk.FreqDist(w.lower() for w in all_tok_words)\n",
        "word_features = list(all_words)[:10000] # with more features, higher accuracy\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['{}'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezgLKQZ8bpwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Naive Bayes classifier\n",
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set_f, test_set_f = featuresets[200:], featuresets[:200]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set_f)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1lFPvxIf-8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "465de09b-9d22-4a35-c998-942e9423964a"
      },
      "source": [
        "# Test the classifier\n",
        "print('The accuracy is ',nltk.classify.accuracy(classifier, test_set_f)*100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is  78.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3-uGEn_hfze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e5d94337-fd4d-4fdf-c7f2-896dbc530c6d"
      },
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "                      mn = True           negati : neutra =     68.7 : 1.0\n",
            "                    rose = True           positi : neutra =     54.9 : 1.0\n",
            "                    down = True           negati : neutra =     49.1 : 1.0\n",
            "               decreased = True           negati : neutra =     34.8 : 1.0\n",
            "                    fell = True           negati : neutra =     26.1 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuRuotbrmXsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "37b0f2aa-298a-4196-d4ee-62f43eeca76f"
      },
      "source": [
        "#testing our model out of train data \n",
        "des_neg = 'the company fell down though they tried hard' #negative\n",
        "des_tok_neg = nltk.tokenize.word_tokenize(des_neg)\n",
        "des_pos = 'The company grew up though the situation was not good' #positive\n",
        "des_tok_pos = nltk.tokenize.word_tokenize(des_pos)\n",
        "print('the sentence given is negative and predicted as ',classifier.classify(document_features(des_tok_neg)))\n",
        "print('the sentence given is positive and predicted as ',classifier.classify(document_features(des_tok_pos)))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the sentence given is negative and predicted as  negative\n",
            "the sentence given is positive and predicted as  positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkVKMNg6qKnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "labels_f = []\n",
        "tests_f = []\n",
        "for i, (feats, label) in enumerate(test_set_f):\n",
        "    observed = classifier.classify(feats)\n",
        "    labels_f.append(label)\n",
        "    tests_f.append(observed)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBHuG2iStBss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "a45d7f8b-4cab-4d60-c046-db507fecff83"
      },
      "source": [
        "print(nltk.ConfusionMatrix(labels_f, tests_f))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         |  n     p |\n",
            "         |  e  n  o |\n",
            "         |  g  e  s |\n",
            "         |  a  u  i |\n",
            "         |  t  t  t |\n",
            "         |  i  r  i |\n",
            "         |  v  a  v |\n",
            "         |  e  l  e |\n",
            "---------+----------+\n",
            "negative |<53> 7  8 |\n",
            " neutral |  3<54> 3 |\n",
            "positive |  5 17<50>|\n",
            "---------+----------+\n",
            "(row = reference; col = test)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdMKpyka2SBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "22c3e6a8-83c1-4dce-d06e-06c77176f328"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "print('precision is ',np.mean(list(precision_score(labels_f, tests_f, average=None, labels=[\"positive\", \"negative\", \"neutral\"]))))\n",
        "print('recall is ',np.mean(list(recall_score(labels_f, tests_f, average=None, labels=[\"positive\", \"negative\", \"neutral\"]))))\n",
        "print('f1_score is ',np.mean(list(f1_score(labels_f, tests_f, average=None, labels=[\"positive\", \"negative\", \"neutral\"]))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision is  0.8195603163159039\n",
            "recall is  0.8177676226852642\n",
            "f1_score is  0.8184520297506358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqTxsBzGM4f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}